{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b71ea3d0-52bd-4bdf-9a01-12e67debd59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532263    3.135494\n",
       "580340    2.484907\n",
       "101839    5.111988\n",
       "438420    4.762174\n",
       "449976    4.094345\n",
       "            ...   \n",
       "269955    4.143135\n",
       "502294    4.997212\n",
       "58461     3.367296\n",
       "647977    5.087596\n",
       "245703    2.890372\n",
       "Name: Calories, Length: 150000, dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "import time\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "# 모델 라이브러리\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "# 데이터 가져오기\n",
    "# 훈련 데이터\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head(1)\n",
    "# 테스트 데이터\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test.head(1)\n",
    "\n",
    "# 수치형 / 범주형 컬럼 나누기\n",
    "# numeric_features = train.select_dtypes(include=['int64','float64'].columns.tolist()\n",
    "numeric_features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "category_features = ['Sex']\n",
    "\n",
    "# 독립변수, Target 설정\n",
    "X = train[numeric_features + category_features]\n",
    "X\n",
    "y = train['Calories']\n",
    "y\n",
    "\n",
    "\n",
    "# 학습 / 검증 데이터 분할 함수\n",
    "num_bins = 20\n",
    "y_binned = pd.cut(y, bins=num_bins, labels=False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y_binned)\n",
    "\n",
    "# Target 데이터 로그변환 : RMSLE 평가지표를 따라가기 위함\n",
    "y_train = np.log1p(y_train)\n",
    "y_train\n",
    "y_val = np.log1p(y_val)\n",
    "y_val\n",
    "\n",
    "# # 데이터 가공\n",
    "# # one-hot encoding, scaler\n",
    "# encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# X_train_category = encoder.fit_transform(X_train[category_features])\n",
    "# X_val_category = encoder.transform(X_val[category_features])\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_numeric = scaler.fit_transform(X_train[numeric_features])\n",
    "# X_val_numeric = scaler.transform(X_val[numeric_features])\n",
    "\n",
    "# # 가공한 데이터 합치기 (numeric+category)\n",
    "# X_train_combined = pd.concat([\n",
    "#         pd.DataFrame(X_train_category, columns=['sex1','sex2']),\n",
    "#         pd.DataFrame(X_train_numeric, columns=numeric_features)\n",
    "#     ], axis=1)\n",
    "# X_val_combined = pd.concat([\n",
    "#         pd.DataFrame(X_val_category, columns=['sex1','sex2']),\n",
    "#         pd.DataFrame(X_val_numeric, columns=numeric_features)\n",
    "#     ], axis=1)\n",
    "\n",
    "\n",
    "# # 모델 생성 / 학습 / 성능비교\n",
    "# models = {\n",
    "#     'XGBoost' : XGBRegressor(random_state=42, n_jobs=-1),\n",
    "#     'RandomForest' : RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "#     'LightGBM' : LGBMRegressor(random_state=42, n_jobs=-1),\n",
    "#     'CatBoost' : CatBoostRegressor(random_seed=42,\n",
    "#                     verbose=100,\n",
    "#                     early_stopping_rounds=50,\n",
    "#                     loss_function='RMSE'\n",
    "#                 )\n",
    "# }\n",
    "\n",
    "# # 각 모델별 하이퍼파라미터 후보군 정의\n",
    "# param_grid = {\n",
    "#     'XGBoost': [\n",
    "#         {'n_estimators':100, 'learning_rate': 0.05, 'max_depth': 4},\n",
    "#         {'n_estimators':200, 'learning_rate': 0.01, 'max_depth': 6}\n",
    "#     ],\n",
    "#     'RandomForest': [\n",
    "#         {'n_estimators': 100, 'max_depth': 5},\n",
    "#         {'n_estimators': 200, 'max_depth': 10}\n",
    "#     ],\n",
    "#     'LightGBM': [\n",
    "#         {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': -1},\n",
    "#         {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 6}\n",
    "#     ],\n",
    "#     'CatBoost': [\n",
    "#         {'iterations': 500, 'learning_rate': 0.05, 'depth': 6, 'l2_leaf_reg': 3, 'subsample': 0.8, 'random_strength': 5},\n",
    "#         {'iterations': 1000, 'learning_rate': 0.1, 'depth': 8, 'l2_leaf_reg': 10, 'subsample': 1.0, 'random_strength': 10}\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# # 교차 검증을 통한 최적 모델 선택\n",
    "# best_score = 0 # 최고 성능 점수\n",
    "# best_model_name = None\n",
    "# best_model = None\n",
    "\n",
    "\n",
    "# # 각 모델과 하이퍼 파라미터 조합에 대해 교차검증 수행\n",
    "# for model_name, model in models.items():\n",
    "#     print(f\"\\n--- Testing {model_name} ---\")\n",
    "#     start_time = time.time()\n",
    "#     for params in param_grid[model_name]:\n",
    "#         model.set_params(**params)\n",
    "#         cv_scores = cross_val_score(model, X_train_combined, y_train, cv=5, scoring='r2')\n",
    "#         mean_cv = np.mean(cv_scores)  # 평균 교차검증 점수\n",
    "#         end_time = time.time()\n",
    "#         elapsed_time = end_time - start_time\n",
    "#         print(f\"Params: {params}, CV R2 Score: {mean_cv:.4f}, Training Time: {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "#         # 최고 성능 모델 업데이트\n",
    "#         if mean_cv > best_score:\n",
    "#             best_score = mean_cv\n",
    "#             best_model_name = model_name\n",
    "#             best_model = model.set_params(**params)\n",
    "\n",
    "\n",
    "# # 최종 선택된 모델로 테스트셋 평가\n",
    "# best_model.fit(X_train_combined, y_train)  # 최적 모델 학습\n",
    "# y_pred = best_model.predict(X_val_combined)  # 테스트셋 예측\n",
    "# test_r2 = r2_score(y_val, y_pred)  # 테스트셋 정확도 계산\n",
    "\n",
    "\n",
    "# # 최고 성능 모델 저장\n",
    "# model_info = {\n",
    "#     'model':best_model,\n",
    "#     'scaler':scaler,\n",
    "#     'encoder':encoder\n",
    "# }\n",
    "# joblib.dump(model_info, 'model.pkl')\n",
    "# # with open('model_info.json', 'w') as f:\n",
    "# #     json.dump(model_info, f)\n",
    "\n",
    "# # 최종 결과 출력\n",
    "# print(f\"\\nBest Model: {best_model_name}\")\n",
    "# print(f\"Best CV Score: {best_score:.4f}\")\n",
    "# print(f\"Test Set R2: {test_r2:.4f}\")\n",
    "# print(\"\\nModel has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f2b4dcd-ab7a-4750-8579-0f47a13fb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd  # 데이터 처리를 위한 pandas\n",
    "import numpy as np  # 수치 계산을 위한 numpy\n",
    "from sklearn.model_selection import train_test_split, cross_val_score  # 데이터 분할 및 교차 검증\n",
    "from sklearn.impute import SimpleImputer  # 결측치 처리\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler  # 범주형 변수 인코딩 및 수치형 변수 스케일링\n",
    "from sklearn.compose import ColumnTransformer  # 컬럼별 전처리 파이프라인 구성\n",
    "from sklearn.pipeline import Pipeline  # 전체 전처리 및 모델링 파이프라인 구성\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet  # 선형 회귀 모델\n",
    "from sklearn.metrics import mean_squared_error, make_scorer  # 모델 평가 지표\n",
    "from sklearn.model_selection import RandomizedSearchCV  # 랜덤 서치를 통한 하이퍼파라미터 튜닝\n",
    "from skopt import BayesSearchCV  # 베이지안 최적화를 통한 하이퍼파라미터 튜닝\n",
    "import xgboost as xgb  # XGBoost 모델\n",
    "import lightgbm as lgb  # LightGBM 모델\n",
    "import warnings  # 경고 메시지 처리\n",
    "import joblib  # 모델 저장 및 로드\n",
    "import os  # 파일 시스템 작업\n",
    "import json  # JSON 파일 처리\n",
    "# LightGBM의 불필요한 경고 메시지 무시 설정\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3448fa4-459d-4b33-b619-050b6619cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_features / category_features\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor= ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, category_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4666f9ff-713a-44a5-9b3c-0411705a530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 / 학습 / 성능비교\n",
    "models = {\n",
    "    'XGBoost' : XGBRegressor(random_state=42, n_jobs=-1),\n",
    "    # 'RandomForest' : RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    'LightGBM' : LGBMRegressor(random_state=42, n_jobs=-1),\n",
    "    'CatBoost' : CatBoostRegressor(random_seed=42,\n",
    "                    verbose=100,\n",
    "                    early_stopping_rounds=50,\n",
    "                    loss_function='RMSE'\n",
    "                )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0708dc91-30b6-4281-b1c9-54fb082a8c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_spaces = {\n",
    "    'XGBoost': {'reg__n_estimators':[100, 200], 'reg__learning_rate': [0.05, 0.1], 'reg__max_depth': [4, 6]},\n",
    "    # 'RandomForest': {'reg__n_estimators': [100,200], 'reg__max_depth': [5 ,10]},\n",
    "    'LightGBM': {'reg__n_estimators': [100,200], 'reg__learning_rate': [0.05, 0.1], 'reg__max_depth': [-1,6]},\n",
    "    'CatBoost': {'reg__iterations': [500,1000], 'reg__learning_rate': [0.05, 0.1], 'reg__depth': [6,8], 'reg__l2_leaf_reg': [3,10], 'reg__subsample': [0.8,1.0], 'reg__random_strength': [5,10]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5819bfe0-d29f-468a-8849-e4b87322c366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== XGBoost ====\n",
      "RMSE: 0.0624\n",
      "\n",
      "==== RandomForest ====\n",
      "RMSE: 0.0639\n",
      "\n",
      "==== LightGBM ====\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 360\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 4.141196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Desktop\\Predict_Calorie_Project\\project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0625\n",
      "\n",
      "==== CatBoost ====\n",
      "Learning rate set to 0.112494\n",
      "0:\tlearn: 0.8622609\ttotal: 163ms\tremaining: 2m 42s\n",
      "100:\tlearn: 0.0612759\ttotal: 3.77s\tremaining: 33.6s\n",
      "200:\tlearn: 0.0592647\ttotal: 7.49s\tremaining: 29.8s\n",
      "300:\tlearn: 0.0584388\ttotal: 11s\tremaining: 25.6s\n",
      "400:\tlearn: 0.0579209\ttotal: 14.6s\tremaining: 21.8s\n",
      "500:\tlearn: 0.0575332\ttotal: 18.3s\tremaining: 18.2s\n",
      "600:\tlearn: 0.0572159\ttotal: 21.8s\tremaining: 14.5s\n",
      "700:\tlearn: 0.0569445\ttotal: 25.3s\tremaining: 10.8s\n",
      "800:\tlearn: 0.0567128\ttotal: 28.8s\tremaining: 7.14s\n",
      "900:\tlearn: 0.0565374\ttotal: 32.2s\tremaining: 3.53s\n",
      "999:\tlearn: 0.0563609\ttotal: 35.6s\tremaining: 0us\n",
      "RMSE: 0.0596\n",
      "\n",
      "==== Final Results ====\n",
      "          Model      RMSE\n",
      "3      CatBoost  0.059594\n",
      "0       XGBoost  0.062413\n",
      "2      LightGBM  0.062539\n",
      "1  RandomForest  0.063941\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 적용 전\n",
    "\n",
    "results = {}  # 결과 저장 딕셔너리\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'\\n==== {name} ====')\n",
    "    try:\n",
    "        # 3.1 전체 파이프라인 구성 (전처리 + 모델)\n",
    "        pipe = Pipeline([\n",
    "            ('preprocessor', preprocessor),  # 전처리 단계\n",
    "            ('reg', model)  # 모델 단계\n",
    "        ])\n",
    "        \n",
    "        # 3.2 모델 학습\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        # 3.3 예측 및 성능 평가\n",
    "        y_pred = pipe.predict(X_val)  # 예측값 생성\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))  # RMSE 계산\n",
    "        print(f'RMSE: {rmse:.4f}')\n",
    "        \n",
    "        results[name] = rmse  # 결과 저장\n",
    "\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# 4. 최종 결과 비교 및 정렬\n",
    "print(\"\\n==== Final Results ====\")\n",
    "results_df = pd.DataFrame(results.items(), columns=['Model', 'RMSE'])  # 결과 데이터프레임 생성\n",
    "results_df = results_df.sort_values('RMSE')  # RMSE 기준 오름차순 정렬\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6111f9e9-c2f1-43ca-9ea8-3ecf5272de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 적용!!!!\n",
    "\n",
    "results = {}  # 모델별 RMSE 결과 저장\n",
    "best_models = {}  # 최적의 모델 저장\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'\\n==== {name} ====')\n",
    "    try:\n",
    "        # 3.1 전체 파이프라인 구성 (전처리 + 모델)\n",
    "        pipe = Pipeline([\n",
    "            ('preprocessor', preprocessor),  # 전처리 단계\n",
    "            ('reg', model)  # 모델 단계\n",
    "        ])\n",
    "\n",
    "        # 베이지안 서치\n",
    "        search = BayesSearchCV(\n",
    "        # 3.2 랜덤 서치를 통한 하이퍼파라미터 최적화\n",
    "        # search = RandomizedSearchCV(\n",
    "            pipe,\n",
    "            param_spaces[name],\n",
    "            n_iter=10,  # 탐색 횟수\n",
    "            cv=5,  # 5-fold 교차 검증\n",
    "            scoring='neg_root_mean_squared_error',  # 평가 지표 (RMSE)\n",
    "            random_state=42,  # 재현성을 위한 시드\n",
    "            n_jobs=-1  # 모든 CPU 코어 사용\n",
    "        )\n",
    "        \n",
    "        # 3.3 모델 학습\n",
    "        search.fit(X_train, y_train)\n",
    "        \n",
    "        # 3.4 최적의 모델 저장\n",
    "        best_models[name] = search.best_estimator_\n",
    "        \n",
    "        # 3.5 교차 검증 결과 계산\n",
    "        cv_scores = -search.cv_results_['mean_test_score']  # RMSE 값 (음수로 저장되어 있어 부호 변환)\n",
    "        rmse = np.mean(cv_scores)  # 평균 RMSE\n",
    "        rmse_std = np.std(cv_scores)  # RMSE 표준편차\n",
    "        \n",
    "        print(f'Best RMSE: {rmse:.4f} (+/- {rmse_std:.4f})')\n",
    "        print(f'Best parameters: {search.best_params_}')\n",
    "    \n",
    "        results[name] = rmse\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# 4. 최종 결과 분석\n",
    "print(\"\\n==== Final Results ====\")\n",
    "results_df = pd.DataFrame(results.items(), columns=['Model', 'RMSE'])\n",
    "results_df = results_df.sort_values('RMSE')  # RMSE 기준 오름차순 정렬\n",
    "print(results_df)\n",
    "\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = best_models[best_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2d11a1f-1af8-432e-937e-a59ddd2ded4a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Pipeline is not fitted yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m----------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Predict_Calorie_Project\\project\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:54\u001b[39m, in \u001b[36m_raise_or_warn_if_not_fitted\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Predict_Calorie_Project\\project\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:787\u001b[39m, in \u001b[36mPipeline.predict\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m     Xt = \u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m].predict(Xt, **params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Predict_Calorie_Project\\project\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Predict_Calorie_Project\\project\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1060\u001b[39m, in \u001b[36mColumnTransformer.transform\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m   1059\u001b[39m _raise_for_params(params, \u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1061\u001b[39m X = _check_X(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Predict_Calorie_Project\\project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1757\u001b[39m, in \u001b[36mcheck_is_fitted\u001b[39m\u001b[34m(estimator, attributes, msg, all_or_any)\u001b[39m\n\u001b[32m   1756\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[32m-> \u001b[39m\u001b[32m1757\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg % {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator).\u001b[34m__name__\u001b[39m})\n",
      "\u001b[31mNotFittedError\u001b[39m: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNotFittedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# test.head()\u001b[39;00m\n\u001b[32m      4\u001b[39m X_test = test[numeric_features + category_features]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m y_pred = \u001b[43mpipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 예측값 생성\u001b[39;00m\n\u001b[32m      7\u001b[39m y_pred = np.exp(y_pred) \n\u001b[32m      9\u001b[39m submission = pd.DataFrame({\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m : test[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mCalories\u001b[39m\u001b[33m'\u001b[39m : y_pred\n\u001b[32m     12\u001b[39m })\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Predict_Calorie_Project\\project\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:782\u001b[39m, in \u001b[36mPipeline.predict\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    740\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Transform the data, and apply `predict` with the final estimator.\u001b[39;00m\n\u001b[32m    741\u001b[39m \n\u001b[32m    742\u001b[39m \u001b[33;03mCall `transform` of each transformer in the pipeline. The transformed\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    779\u001b[39m \u001b[33;03m    Result of calling `predict` on the final estimator.\u001b[39;00m\n\u001b[32m    780\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    781\u001b[39m \u001b[38;5;66;03m# TODO(1.8): Remove the context manager and use check_is_fitted(self)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_raise_or_warn_if_not_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_routing_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.12-windows-x86_64-none\\Lib\\contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    156\u001b[39m     value = typ()\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Predict_Calorie_Project\\project\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:56\u001b[39m, in \u001b[36m_raise_or_warn_if_not_fitted\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[33m\"\u001b[39m\u001b[33mPipeline is not fitted yet.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# we only get here if the above didn't raise\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mNotFittedError\u001b[39m: Pipeline is not fitted yet."
     ]
    }
   ],
   "source": [
    "best_model = models['CatBoost']\n",
    "\n",
    "# test.head()\n",
    "X_test = test[numeric_features + category_features]\n",
    "\n",
    "y_pred = pipe.predict(X_test)  # 예측값 생성\n",
    "y_pred = np.exp(y_pred) \n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id' : test['id'],\n",
    "    'Calories' : y_pred\n",
    "})\n",
    "# 현재 날짜와 시간을 파일명에 포함\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "submission.to_csv(f'submission_{current_time}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7786b927-9bc3-4280-858d-d46953040996",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "There is no trained model to use predict(). Use fit() to train model. Then use this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m----------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCatBoostError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# test.head()\u001b[39;00m\n\u001b[32m      4\u001b[39m X_test = test[numeric_features + category_features]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m y_pred = \u001b[43mbest_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 예측값 생성\u001b[39;00m\n\u001b[32m      7\u001b[39m y_pred = np.exp(y_pred) \n\u001b[32m      9\u001b[39m submission = pd.DataFrame({\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m : test[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mCalories\u001b[39m\u001b[33m'\u001b[39m : y_pred\n\u001b[32m     12\u001b[39m })\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Predict_Calorie_Project\\project\\.venv\\Lib\\site-packages\\catboost\\core.py:5924\u001b[39m, in \u001b[36mCatBoostRegressor.predict\u001b[39m\u001b[34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[39m\n\u001b[32m   5922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prediction_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5923\u001b[39m     prediction_type = \u001b[38;5;28mself\u001b[39m._get_default_prediction_type()\n\u001b[32m-> \u001b[39m\u001b[32m5924\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpredict\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Predict_Calorie_Project\\project\\.venv\\Lib\\site-packages\\catboost\\core.py:2620\u001b[39m, in \u001b[36mCatBoost._predict\u001b[39m\u001b[34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[39m\n\u001b[32m   2618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2619\u001b[39m     verbose = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2620\u001b[39m data, data_is_single_object = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_predict_input_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_method_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2621\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_prediction_type(prediction_type)\n\u001b[32m   2623\u001b[39m predictions = \u001b[38;5;28mself\u001b[39m._base_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Predict_Calorie_Project\\project\\.venv\\Lib\\site-packages\\catboost\\core.py:2596\u001b[39m, in \u001b[36mCatBoost._process_predict_input_data\u001b[39m\u001b[34m(self, data, parent_method_name, thread_count, label)\u001b[39m\n\u001b[32m   2594\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_process_predict_input_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, parent_method_name, thread_count, label=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2595\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_fitted() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tree_count_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2596\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError((\u001b[33m\"\u001b[39m\u001b[33mThere is no trained model to use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m(). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2597\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33mUse fit() to train model. Then use this method.\u001b[39m\u001b[33m\"\u001b[39m).format(parent_method_name))\n\u001b[32m   2598\u001b[39m     is_single_object = _is_data_single_object(data)\n\u001b[32m   2599\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Pool):\n",
      "\u001b[31mCatBoostError\u001b[39m: There is no trained model to use predict(). Use fit() to train model. Then use this method."
     ]
    }
   ],
   "source": [
    "best_model\n",
    "\n",
    "# test.head()\n",
    "X_test = test[numeric_features + category_features]\n",
    "\n",
    "y_pred = best_model.predict(X_test)  # 예측값 생성\n",
    "y_pred = np.exp(y_pred) \n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id' : test['id'],\n",
    "    'Calories' : y_pred\n",
    "})\n",
    "# 현재 날짜와 시간을 파일명에 포함\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "submission.to_csv(f'submission_{current_time}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
