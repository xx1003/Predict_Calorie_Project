{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58cd6269-2a8d-47f5-b0a5-9f7157e222a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경설정\n",
    "import matplotlib.pyplot as plt \n",
    "# 한글출력\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic' #  Windows 'Malgun Gothic' \n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "794f36cc-28d3-4f07-9cbe-f1493fd83c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "import time\n",
    "import joblib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d64ecf00-507d-43a7-9d4d-5aa12a8b5391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>Body_Temp</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>36</td>\n",
       "      <td>189.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   Sex  Age  Height  Weight  Duration  Heart_Rate  Body_Temp  Calories\n",
       "0   0  male   36   189.0    82.0      26.0       101.0       41.0     150.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 가져오기\n",
    "import pandas as pd\n",
    "\n",
    "# 훈련 데이터\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "583163cb-0561-4387-aba4-89fa30c4c88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>Body_Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750000</td>\n",
       "      <td>male</td>\n",
       "      <td>45</td>\n",
       "      <td>177.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>39.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   Sex  Age  Height  Weight  Duration  Heart_Rate  Body_Temp\n",
       "0  750000  male   45   177.0    81.0       7.0        87.0       39.8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fb74613-903d-48e0-9ffa-4dd3241b3593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "Sex           0\n",
       "Age           0\n",
       "Height        0\n",
       "Weight        0\n",
       "Duration      0\n",
       "Heart_Rate    0\n",
       "Body_Temp     0\n",
       "Calories      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "554a3f3f-ab9f-4676-be5d-59aa8dcdf5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         150.0\n",
       "1          34.0\n",
       "2          29.0\n",
       "3         140.0\n",
       "4         146.0\n",
       "          ...  \n",
       "749995    230.0\n",
       "749996     96.0\n",
       "749997    221.0\n",
       "749998    109.0\n",
       "749999    103.0\n",
       "Name: Calories, Length: 750000, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 수치형 / 범주형 컬럼 나누기\n",
    "numeric_features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "category_features = ['Sex']\n",
    "\n",
    "# 독립변수, Target 설정\n",
    "X = train[numeric_features + category_features]\n",
    "X\n",
    "\n",
    "y = train['Calories']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9472f171-1097-4c0b-b562-00d9ba10dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/검증 데이터 분할 함수\n",
    "def data_seperate(X_df, y_series):\n",
    "    num_bins = 20\n",
    "    y_binned = pd.cut(y, bins=num_bins, labels=False)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_df, y_series, test_size=0.2, random_state=42, stratify=y_binned)\n",
    "\n",
    "    return [X_train, X_val, y_train, y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4209e60-ce07-4e9e-b5b0-76c8fa2bba3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600000, 7), (150000, 7), (600000,), (150000,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = data_seperate(X, y)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bd27de7-4b8d-4b52-b1f2-1fa473f7f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 데이터 인코딩 함수\n",
    "def category_encoding(category_data):\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    return encoder.fit_transform(category_data)\n",
    "\n",
    "# 수치형 데이터 인코딩 함수\n",
    "def numeric_encoding(numeric_data):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(numeric_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "960edbb0-586d-4ab1-b3e5-fa8e1bd7a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩 데이터 합체 함수\n",
    "def data_concat(category_data, numeric_data):\n",
    "    train_combined = pd.concat([\n",
    "        pd.DataFrame(category_data, columns=['sex1','sex2']),\n",
    "        pd.DataFrame(numeric_data, columns=numeric_features)\n",
    "    ], axis=1)\n",
    "    return train_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8320cd69-187b-4ce7-88dd-6469549ac94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532263    3.135494\n",
       "580340    2.484907\n",
       "101839    5.111988\n",
       "438420    4.762174\n",
       "449976    4.094345\n",
       "            ...   \n",
       "269955    4.143135\n",
       "502294    4.997212\n",
       "58461     3.367296\n",
       "647977    5.087596\n",
       "245703    2.890372\n",
       "Name: Calories, Length: 150000, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target 데이터 로그변환 : RMSLE 평가지표를 따라가기 위함\n",
    "y_train = np.log1p(y_train)\n",
    "y_train\n",
    "y_val = np.log1p(y_val)\n",
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8a45ace6-f8aa-4769-af44-916f057d4629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가지표 함수\n",
    "def score_model(y_val_df, y_pred_df):\n",
    "    print(\"검증 데이터 성능:\")\n",
    "    print(f\"RMSLE: {np.sqrt(mean_squared_error(np.log1p(y_val_df), np.log1p(y_pred_df))):.10f}\")\n",
    "    print(f\"RMSE: {mean_squared_error(y_val_df, y_pred_df):.2f}\")\n",
    "    print(f\"R2 Score: {r2_score(y_val_df, y_pred_df):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15bcc357-07db-4def-b0ef-b9427e1c962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 라이브러리\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e370811a-536f-483c-8570-f0473492a411",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_train_category = encoder.fit_transform(X_train[category_features])\n",
    "X_val_category = encoder.transform(X_val[category_features])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_numeric = scaler.fit_transform(X_train[numeric_features])\n",
    "X_val_numeric = scaler.transform(X_val[numeric_features])\n",
    "\n",
    "# X_train_category, X_val_category = category_encoding(X_train[category_features]), category_encoding(X_val[category_features])\n",
    "# X_train_numeric, X_val_numeric = numeric_encoding(X_train[numeric_features]), numeric_encoding(X_val[numeric_features])\n",
    "\n",
    "X_train_combined = data_concat(X_train_category, X_train_numeric)\n",
    "X_val_combined = data_concat(X_val_category, X_val_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b734f-1079-43c1-88ff-bc902e46659f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing XGBoost ---\n",
      "Params: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 4}, CV R2 Score: 0.9944, Training Time: 1.93 seconds\n",
      "Params: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 6}, CV R2 Score: 0.9737, Training Time: 7.13 seconds\n",
      "\n",
      "--- Testing RandomForest ---\n",
      "Params: {'n_estimators': 100, 'max_depth': None}, CV R2 Score: 0.9956, Training Time: 71.21 seconds\n",
      "Params: {'n_estimators': 200, 'max_depth': 10}, CV R2 Score: 0.9942, Training Time: 139.87 seconds\n",
      "\n",
      "--- Testing LightGBM ---\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 359\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 4.141523\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 363\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 4.139645\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 363\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 4.142729\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 361\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 4.140862\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 361\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 4.141223\n",
      "Params: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': -1}, CV R2 Score: 0.9953, Training Time: 3.37 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 359\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 4.141523\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 363\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 4.139645\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 363\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 4.142729\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 361\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 4.140862\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 361\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 4.141223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Params: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 6}, CV R2 Score: 0.9959, Training Time: 7.86 seconds\n",
      "\n",
      "--- Testing CatBoost ---\n",
      "0:\tlearn: 0.9193261\ttotal: 13.2ms\tremaining: 6.61s\n",
      "100:\tlearn: 0.0740597\ttotal: 1.3s\tremaining: 5.13s\n",
      "200:\tlearn: 0.0638931\ttotal: 2.55s\tremaining: 3.79s\n",
      "300:\tlearn: 0.0612679\ttotal: 3.82s\tremaining: 2.53s\n",
      "400:\tlearn: 0.0600265\ttotal: 5.07s\tremaining: 1.25s\n",
      "499:\tlearn: 0.0592842\ttotal: 6.34s\tremaining: 0us\n",
      "0:\tlearn: 0.9194820\ttotal: 14.1ms\tremaining: 7.05s\n",
      "100:\tlearn: 0.0733714\ttotal: 1.28s\tremaining: 5.07s\n",
      "200:\tlearn: 0.0639458\ttotal: 2.5s\tremaining: 3.72s\n",
      "300:\tlearn: 0.0612694\ttotal: 3.75s\tremaining: 2.48s\n",
      "400:\tlearn: 0.0599611\ttotal: 5s\tremaining: 1.23s\n",
      "499:\tlearn: 0.0592028\ttotal: 6.24s\tremaining: 0us\n",
      "0:\tlearn: 0.9187257\ttotal: 12.7ms\tremaining: 6.36s\n",
      "100:\tlearn: 0.0742394\ttotal: 1.29s\tremaining: 5.1s\n",
      "200:\tlearn: 0.0644123\ttotal: 2.53s\tremaining: 3.77s\n",
      "300:\tlearn: 0.0613332\ttotal: 3.77s\tremaining: 2.49s\n",
      "400:\tlearn: 0.0599673\ttotal: 5.03s\tremaining: 1.24s\n",
      "499:\tlearn: 0.0592128\ttotal: 6.27s\tremaining: 0us\n",
      "0:\tlearn: 0.9197610\ttotal: 13.2ms\tremaining: 6.59s\n",
      "100:\tlearn: 0.0741127\ttotal: 1.29s\tremaining: 5.09s\n",
      "200:\tlearn: 0.0645092\ttotal: 2.51s\tremaining: 3.74s\n",
      "300:\tlearn: 0.0614726\ttotal: 3.75s\tremaining: 2.48s\n",
      "400:\tlearn: 0.0600629\ttotal: 5.01s\tremaining: 1.24s\n",
      "499:\tlearn: 0.0592722\ttotal: 6.25s\tremaining: 0us\n",
      "0:\tlearn: 0.9193037\ttotal: 13.5ms\tremaining: 6.72s\n",
      "100:\tlearn: 0.0737223\ttotal: 1.27s\tremaining: 5.03s\n",
      "200:\tlearn: 0.0639456\ttotal: 2.51s\tremaining: 3.73s\n",
      "300:\tlearn: 0.0611821\ttotal: 3.75s\tremaining: 2.48s\n",
      "400:\tlearn: 0.0599459\ttotal: 4.99s\tremaining: 1.23s\n",
      "499:\tlearn: 0.0592491\ttotal: 6.22s\tremaining: 0us\n",
      "Params: {'iterations': 500, 'learning_rate': 0.05, 'depth': 6, 'l2_leaf_reg': 3, 'subsample': 0.8, 'random_strength': 5}, CV R2 Score: 0.9960, Training Time: 32.26 seconds\n",
      "0:\tlearn: 0.8757661\ttotal: 16ms\tremaining: 15.9s\n",
      "100:\tlearn: 0.0638303\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.0598490\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.0587915\ttotal: 4.39s\tremaining: 10.2s\n",
      "400:\tlearn: 0.0581045\ttotal: 5.81s\tremaining: 8.68s\n",
      "500:\tlearn: 0.0576082\ttotal: 7.23s\tremaining: 7.2s\n",
      "600:\tlearn: 0.0572027\ttotal: 8.66s\tremaining: 5.75s\n",
      "700:\tlearn: 0.0568391\ttotal: 10.1s\tremaining: 4.32s\n",
      "800:\tlearn: 0.0565076\ttotal: 11.6s\tremaining: 2.87s\n",
      "900:\tlearn: 0.0562114\ttotal: 13s\tremaining: 1.42s\n",
      "999:\tlearn: 0.0559724\ttotal: 14.4s\tremaining: 0us\n",
      "0:\tlearn: 0.8758950\ttotal: 16.5ms\tremaining: 16.5s\n",
      "100:\tlearn: 0.0640775\ttotal: 1.49s\tremaining: 13.3s\n",
      "200:\tlearn: 0.0597317\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.0584323\ttotal: 4.43s\tremaining: 10.3s\n",
      "400:\tlearn: 0.0577913\ttotal: 5.86s\tremaining: 8.75s\n",
      "500:\tlearn: 0.0573020\ttotal: 7.28s\tremaining: 7.25s\n",
      "600:\tlearn: 0.0569125\ttotal: 8.69s\tremaining: 5.77s\n",
      "700:\tlearn: 0.0565744\ttotal: 10.1s\tremaining: 4.32s\n",
      "800:\tlearn: 0.0562802\ttotal: 11.5s\tremaining: 2.87s\n",
      "900:\tlearn: 0.0559668\ttotal: 12.9s\tremaining: 1.42s\n",
      "999:\tlearn: 0.0556976\ttotal: 14.3s\tremaining: 0us\n",
      "0:\tlearn: 0.8752801\ttotal: 24.4ms\tremaining: 24.4s\n",
      "100:\tlearn: 0.0637289\ttotal: 1.5s\tremaining: 13.3s\n",
      "200:\tlearn: 0.0596737\ttotal: 2.97s\tremaining: 11.8s\n",
      "300:\tlearn: 0.0584181\ttotal: 4.43s\tremaining: 10.3s\n",
      "400:\tlearn: 0.0577189\ttotal: 5.91s\tremaining: 8.84s\n",
      "500:\tlearn: 0.0572072\ttotal: 7.39s\tremaining: 7.36s\n",
      "600:\tlearn: 0.0568150\ttotal: 8.85s\tremaining: 5.88s\n",
      "700:\tlearn: 0.0564791\ttotal: 10.3s\tremaining: 4.4s\n",
      "800:\tlearn: 0.0562147\ttotal: 11.7s\tremaining: 2.9s\n",
      "900:\tlearn: 0.0559426\ttotal: 13.1s\tremaining: 1.44s\n",
      "999:\tlearn: 0.0556857\ttotal: 14.5s\tremaining: 0us\n",
      "0:\tlearn: 0.8762376\ttotal: 16.9ms\tremaining: 16.9s\n",
      "100:\tlearn: 0.0646183\ttotal: 1.47s\tremaining: 13.1s\n",
      "200:\tlearn: 0.0598205\ttotal: 2.96s\tremaining: 11.8s\n",
      "300:\tlearn: 0.0585131\ttotal: 4.46s\tremaining: 10.3s\n",
      "400:\tlearn: 0.0578229\ttotal: 5.92s\tremaining: 8.84s\n",
      "500:\tlearn: 0.0573366\ttotal: 7.33s\tremaining: 7.31s\n",
      "600:\tlearn: 0.0569981\ttotal: 8.72s\tremaining: 5.79s\n",
      "700:\tlearn: 0.0566711\ttotal: 10.1s\tremaining: 4.33s\n",
      "800:\tlearn: 0.0564258\ttotal: 11.5s\tremaining: 2.87s\n",
      "900:\tlearn: 0.0561965\ttotal: 12.9s\tremaining: 1.42s\n",
      "999:\tlearn: 0.0559433\ttotal: 14.3s\tremaining: 0us\n",
      "0:\tlearn: 0.8757296\ttotal: 16.9ms\tremaining: 16.9s\n",
      "100:\tlearn: 0.0643004\ttotal: 1.48s\tremaining: 13.2s\n",
      "200:\tlearn: 0.0597294\ttotal: 2.95s\tremaining: 11.7s\n",
      "300:\tlearn: 0.0585250\ttotal: 4.42s\tremaining: 10.3s\n",
      "400:\tlearn: 0.0579374\ttotal: 5.83s\tremaining: 8.71s\n",
      "500:\tlearn: 0.0575164\ttotal: 7.2s\tremaining: 7.17s\n",
      "600:\tlearn: 0.0571618\ttotal: 8.64s\tremaining: 5.74s\n",
      "700:\tlearn: 0.0567950\ttotal: 10.1s\tremaining: 4.29s\n",
      "800:\tlearn: 0.0564855\ttotal: 11.5s\tremaining: 2.85s\n",
      "900:\tlearn: 0.0561879\ttotal: 12.9s\tremaining: 1.42s\n",
      "999:\tlearn: 0.0558804\ttotal: 14.4s\tremaining: 0us\n",
      "Params: {'iterations': 1000, 'learning_rate': 0.1, 'depth': 8, 'l2_leaf_reg': 10, 'subsample': 1.0, 'random_strength': 10}, CV R2 Score: 0.9962, Training Time: 105.41 seconds\n",
      "0:\tlearn: 0.8757910\ttotal: 19.4ms\tremaining: 19.4s\n",
      "100:\tlearn: 0.0636530\ttotal: 1.75s\tremaining: 15.6s\n",
      "200:\tlearn: 0.0598859\ttotal: 3.48s\tremaining: 13.8s\n",
      "300:\tlearn: 0.0587807\ttotal: 5.22s\tremaining: 12.1s\n",
      "400:\tlearn: 0.0581555\ttotal: 6.97s\tremaining: 10.4s\n",
      "500:\tlearn: 0.0577381\ttotal: 8.67s\tremaining: 8.64s\n",
      "600:\tlearn: 0.0573713\ttotal: 10.4s\tremaining: 6.9s\n",
      "700:\tlearn: 0.0570312\ttotal: 12.1s\tremaining: 5.17s\n",
      "800:\tlearn: 0.0567301\ttotal: 13.9s\tremaining: 3.44s\n",
      "900:\tlearn: 0.0564572\ttotal: 15.5s\tremaining: 1.7s\n",
      "999:\tlearn: 0.0562246\ttotal: 17.2s\tremaining: 0us\n",
      "\n",
      "Best Model: CatBoost\n",
      "Best CV Score: 0.9962\n",
      "Test Set R2: 0.9962\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'XGBoost' : XGBRegressor(random_state=42, n_jobs=-1),\n",
    "    'RandomForest' : RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    'LightGBM' : LGBMRegressor(random_state=42, n_jobs=-1),\n",
    "    'CatBoost' : CatBoostRegressor(random_seed=42,\n",
    "                    verbose=100,\n",
    "                    early_stopping_rounds=50,\n",
    "                    loss_function='RMSE'\n",
    "                )\n",
    "}\n",
    "\n",
    "# 각 모델별 하이퍼파라미터 후보군 정의\n",
    "param_grid = {\n",
    "    'XGBoost': [\n",
    "        {'n_estimators':100, 'learning_rate': 0.05, 'max_depth': 4},\n",
    "        {'n_estimators':200, 'learning_rate': 0.01, 'max_depth': 6}\n",
    "    ],\n",
    "    'RandomForest': [\n",
    "        {'n_estimators': 100, 'max_depth': None},\n",
    "        {'n_estimators': 200, 'max_depth': 10}\n",
    "    ],\n",
    "    'LightGBM': [\n",
    "        {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': -1},\n",
    "        {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 6}\n",
    "    ],\n",
    "    'CatBoost': [\n",
    "        {'iterations': 500, 'learning_rate': 0.05, 'depth': 6, 'l2_leaf_reg': 3, 'subsample': 0.8, 'random_strength': 5},\n",
    "        {'iterations': 1000, 'learning_rate': 0.1, 'depth': 8, 'l2_leaf_reg': 10, 'subsample': 1.0, 'random_strength': 10}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 교차 검증을 통한 최적 모델 선택\n",
    "best_score = 0 # 최고 성능 점수\n",
    "best_model_name = None\n",
    "best_model = None\n",
    "\n",
    "\n",
    "# 각 모델과 하이퍼 파라미터 조합에 대해 교차검증 수행\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n--- Testing {model_name} ---\")\n",
    "    start_time = time.time()\n",
    "    for params in param_grid[model_name]:\n",
    "        model.set_params(**params)\n",
    "        cv_scores = cross_val_score(model, X_train_combined, y_train, cv=5, scoring='r2')\n",
    "        mean_cv = np.mean(cv_scores)  # 평균 교차검증 점수\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Params: {params}, CV R2 Score: {mean_cv:.4f}, Training Time: {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        # 최고 성능 모델 업데이트\n",
    "        if mean_cv > best_score:\n",
    "            best_score = mean_cv\n",
    "            best_model_name = model_name\n",
    "            best_model = model.set_params(**params)\n",
    "\n",
    "\n",
    "# 최종 선택된 모델로 테스트셋 평가\n",
    "best_model.fit(X_train_combined, y_train)  # 최적 모델 학습\n",
    "y_pred = best_model.predict(X_val_combined)  # 테스트셋 예측\n",
    "test_r2 = r2_score(y_val, y_pred)  # 테스트셋 정확도 계산\n",
    "\n",
    "# test.csv 데이터 예측\n",
    "test_predict(best_model)\n",
    "\n",
    "# 최고 성능 모델 저장\n",
    "model_info = {\n",
    "    'model':best_model,\n",
    "    'scaler':scaler,\n",
    "    'encoder':encoder\n",
    "}\n",
    "joblib.dump(model_info, 'model.pkl')\n",
    "\n",
    "# 최종 결과 출력\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Best CV Score: {best_score:.4f}\")\n",
    "print(f\"Test Set R2: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "69ff7bcf-892e-40ed-a29d-109d56573a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost\n",
      "검증 데이터 성능:\n",
      "RMSLE: 0.0209195477\n",
      "RMSE: 0.01\n",
      "R2 Score: 0.99\n",
      "\n",
      "random forest\n",
      "검증 데이터 성능:\n",
      "RMSLE: 0.0182104888\n",
      "RMSE: 0.00\n",
      "R2 Score: 1.00\n",
      "\n",
      "lightgbm\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 360\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 4.141196\n",
      "검증 데이터 성능:\n",
      "RMSLE: 0.0182104888\n",
      "RMSE: 0.00\n",
      "R2 Score: 1.00\n",
      "\n",
      "catboost\n",
      "0:\tlearn: 0.9188701\ttest: 0.9199195\tbest: 0.9199195 (0)\ttotal: 17.6ms\tremaining: 17.5s\n",
      "100:\tlearn: 0.0733049\ttest: 0.0735699\tbest: 0.0735699 (100)\ttotal: 1.41s\tremaining: 12.5s\n",
      "200:\tlearn: 0.0638636\ttest: 0.0643988\tbest: 0.0643988 (200)\ttotal: 2.72s\tremaining: 10.8s\n",
      "300:\tlearn: 0.0613750\ttest: 0.0620603\tbest: 0.0620603 (300)\ttotal: 4.07s\tremaining: 9.44s\n",
      "400:\tlearn: 0.0602408\ttest: 0.0610857\tbest: 0.0610857 (400)\ttotal: 5.46s\tremaining: 8.15s\n",
      "500:\tlearn: 0.0596024\ttest: 0.0605926\tbest: 0.0605926 (500)\ttotal: 6.84s\tremaining: 6.81s\n",
      "600:\tlearn: 0.0591705\ttest: 0.0603235\tbest: 0.0603235 (600)\ttotal: 8.22s\tremaining: 5.46s\n",
      "700:\tlearn: 0.0588626\ttest: 0.0601421\tbest: 0.0601421 (700)\ttotal: 9.56s\tremaining: 4.08s\n",
      "800:\tlearn: 0.0586205\ttest: 0.0599948\tbest: 0.0599948 (800)\ttotal: 10.9s\tremaining: 2.71s\n",
      "900:\tlearn: 0.0584127\ttest: 0.0599016\tbest: 0.0599016 (900)\ttotal: 12.3s\tremaining: 1.35s\n",
      "999:\tlearn: 0.0582507\ttest: 0.0598414\tbest: 0.0598414 (999)\ttotal: 13.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.05984137257\n",
      "bestIteration = 999\n",
      "\n",
      "검증 데이터 성능:\n",
      "RMSLE: 0.0171365461\n",
      "RMSE: 0.00\n",
      "R2 Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# 모델 사용 코드\n",
    "# 새 모델 추가하고 싶으면 여기만 수정\n",
    "# 독립변수 데이터 인코딩\n",
    "# 훈련 데이터\n",
    "X_train_category, X_val_category = category_encoding(X_train[category_features]), category_encoding(X_val[category_features])\n",
    "X_train_numeric, X_val_numeric = numeric_encoding(X_train[numeric_features]), numeric_encoding(X_val[numeric_features])\n",
    "\n",
    "X_train_combined = data_concat(X_train_category, X_train_numeric)\n",
    "X_val_combined = data_concat(X_val_category, X_val_numeric)\n",
    "\n",
    "# print(X_train_combined.head())\n",
    "# print(X_val_combined.head())\n",
    "\n",
    "# 모델 적용\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1)\n",
    "lgb_model = LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=-1, random_state=42, n_jobs=-1)\n",
    "cat_model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=10,\n",
    "    subsample=0.8,\n",
    "    random_strength=5,\n",
    "    loss_function='RMSE',\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=100,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "print(\"xgboost\")\n",
    "xgb_model.fit(X_train_combined, y_train)\n",
    "xgb_pred = xgb_model.predict(X_val_combined)\n",
    "score_model(y_val, xgb_pred)\n",
    "\n",
    "print(\"\\nrandom forest\")\n",
    "rf_model.fit(X_train_combined, y_train)\n",
    "rf_pred = rf_model.predict(X_val_combined)\n",
    "score_model(y_val, rf_pred)\n",
    "\n",
    "print(\"\\nlightgbm\")\n",
    "lgb_model.fit(X_train_combined, y_train)\n",
    "lgb_pred = rf_model.predict(X_val_combined)\n",
    "score_model(y_val, lgb_pred)\n",
    "\n",
    "print(\"\\ncatboost\")\n",
    "cat_model.fit(X_train_combined, y_train, eval_set=(X_val_combined, y_val))\n",
    "cat_pred = cat_model.predict(X_val_combined)\n",
    "score_model(y_val, cat_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94e935b3-e10f-4d95-8bda-416ac03eaff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 인코딩\n",
    "def test_predict(model):\n",
    "    test_category = category_encoding(test[category_features])\n",
    "    test_numeric = numeric_encoding(test[numeric_features])\n",
    "    test_combined = data_concat(test_category, test_numeric)\n",
    "    \n",
    "    test_pred = model.predict(test_combined)\n",
    "    test_pred = np.exp(test_pred)\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0458b580-8cde-493c-8125-3197a571ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_kaggle(test_pred_data):\n",
    "    # 제출 파일 생성, 공모전 제출 양식 준수\n",
    "    submission = pd.DataFrame({\n",
    "        'id' : test['id'],\n",
    "        'Calories' : test_pred_data\n",
    "    })\n",
    "    # 현재 날짜와 시간을 파일명에 포함\n",
    "    current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    submission.to_csv(f'submission_{current_time}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab3c5441-6548-48b1-81f8-77edb6bc4b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_kaggle(test_predict(best_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
